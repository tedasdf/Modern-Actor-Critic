# General training settings
# config.yaml
seed: 42
num_epoch: 1000        # total episodes
num_step: 100         # steps per episode
num_workers: 4
env_id: "Pendulum-v1"
minibatch_size: 8

agent_continuous:
  _target_: PPO.agent.PPOagent        # or your A2C/PPO agent class
  hidden_dim: 256          # default hidden layer size
  gamma: 0.99
  epsilon: 0.2
  kl_target: 0.01
  act_lr: 3e-4
  critic_lr: 3e-4
  lam: 0.95 
  entropy_coef: 0.02