program: PPO/train.py
program: -m
command:
  - C:\Users\teeds\Documents\GitHub\empty\Modern-Actor-Critic\.remake\Scripts\python.exe
  - -m
  - PPO.train
  - ${args}

# sweep.yaml
method: random      # or grid / bayes
metric:
  name: eval/return_mean
  goal: maximize

parameters:
  hidden_dim:
    distribution: int_uniform
    min: 128
    max: 256

  act_lr:
    distribution: uniform
    min: 1e-4
    max: 1e-3

  critic_lr:
    distribution: uniform
    min: 1e-4
    max: 1e-3

  seed:
    values: [42, 123, 2026]  # optional: multiple seeds for robustness

  # optional: rollout_length sweep
  # rollout_length:
  #   values: [20, 40, 60]

